{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T13:10:47.487099Z","iopub.status.busy":"2024-05-19T13:10:47.486747Z","iopub.status.idle":"2024-05-19T13:10:56.127059Z","shell.execute_reply":"2024-05-19T13:10:56.126095Z","shell.execute_reply.started":"2024-05-19T13:10:47.487066Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data as data\n","from torchvision import datasets, transforms, utils\n","import os\n","import random\n","from collections import defaultdict\n","from PIL import Image\n","from PIL import ImageFile\n","ImageFile.LOAD_TRUNCATED_IMAGES = True\n","\n","\n","from kaggle_secrets import UserSecretsClient\n","user_secrets = UserSecretsClient()\n","wandb_api_key = user_secrets.get_secret(\"wandb-api-key\")\n","\n","root_dir = '/kaggle/input/intel-image-classification'\n","\n","import wandb\n","wandb.login(key=wandb_api_key)"]},{"cell_type":"markdown","metadata":{},"source":["# Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T13:10:56.129055Z","iopub.status.busy":"2024-05-19T13:10:56.128630Z","iopub.status.idle":"2024-05-19T13:10:56.133619Z","shell.execute_reply":"2024-05-19T13:10:56.132773Z","shell.execute_reply.started":"2024-05-19T13:10:56.129029Z"},"trusted":true},"outputs":[],"source":["batch_size = 32\n","n_kernels = 64\n","n_epochs = 500\n","learning_rate = 1e-3\n","dropout = 0.2\n","limit_per_class = 0  # 0 to disable\n","seed = 42\n","save_every = 1"]},{"cell_type":"markdown","metadata":{},"source":["# WandB"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T13:10:56.135475Z","iopub.status.busy":"2024-05-19T13:10:56.135214Z","iopub.status.idle":"2024-05-19T13:11:13.326132Z","shell.execute_reply":"2024-05-19T13:11:13.325124Z","shell.execute_reply.started":"2024-05-19T13:10:56.135446Z"},"trusted":true},"outputs":[],"source":["model_name = \"ResNet-IntelImage\"\n","\n","wandb.init(\n","    project=\"deep-learning\",\n","    config={\n","        \"model\": model_name,\n","        \"batch_size\": batch_size,\n","        \"n_kernels\": n_kernels,\n","        \"n_epochs\": n_epochs,\n","        \"learning_rate\": learning_rate,\n","        \"dropout\": dropout,\n","        \"seed\": seed,\n","        \"limit_per_class\": limit_per_class,\n","    }\n",")"]},{"cell_type":"markdown","metadata":{},"source":["# IntelImageDataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T13:11:13.329376Z","iopub.status.busy":"2024-05-19T13:11:13.329009Z","iopub.status.idle":"2024-05-19T13:11:13.347750Z","shell.execute_reply":"2024-05-19T13:11:13.346985Z","shell.execute_reply.started":"2024-05-19T13:11:13.329341Z"},"trusted":true},"outputs":[],"source":["class IntelImageDataset(data.Dataset):\n","    def __init__(self, root_dir=root_dir, train=True, seed=seed, limit_per_class=limit_per_class):\n","        super().__init__()\n","\n","        # params dataset\n","        self.root_dir = root_dir\n","        self.train = train\n","        self.limit_per_class = limit_per_class\n","\n","        # data and labels\n","        self.image_paths = []\n","        self.labels = []\n","\n","        self.number_of_classes = 0\n","        self.classes = []\n","\n","        self.transform = transforms.Compose([\n","            transforms.Resize((256, 256)),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.RandomVerticalFlip(),\n","            transforms.RandomRotation(degrees=30), # degrees = range of rotation\n","            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1), # parameters are ranges\n","            transforms.RandomGrayscale(p=0.1), # p = probability of applying the transform\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","        ])\n","\n","        data_dir = os.path.join(root_dir, 'seg_train/seg_train' if train else 'seg_test/seg_test')\n","\n","        # Iterate through class folders within the alphabetical folder\n","        for class_name in os.listdir(data_dir):\n","            class_dir = os.path.join(data_dir, class_name)\n","            if not os.path.isdir(class_dir):\n","                continue  # Skip if not a directory\n","\n","            filenames = sorted(os.listdir(class_dir))\n","            count = 0\n","            for filename in filenames:\n","                if limit_per_class == 0 or count < limit_per_class:\n","                    try:\n","                      img_path = os.path.join(class_dir, filename)\n","\n","                      Image.open(img_path).verify()\n","\n","                      self.image_paths.append(img_path)\n","                      self.labels.append(self.number_of_classes)\n","\n","                      count += 1\n","\n","                    except (IOError, SyntaxError):\n","                      print(\n","                          'Corrupted image or non-image file detected and skipped:', filename)\n","                else:\n","                    break\n","                    \n","            self.number_of_classes += 1\n","            self.classes.append(class_name)\n","\n","        random.seed(seed)\n","        combined = list(zip(self.image_paths, self.labels))\n","        random.shuffle(combined)\n","        self.image_paths, self.labels = zip(*combined)\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, index):\n","        image_path = self.image_paths[index]\n","        label = self.labels[index]\n","\n","        try:\n","          image = Image.open(image_path)\n","          op = 1\n","          image = image.convert('RGB')\n","          rgb = 1\n","        except (IOError, SyntaxError):\n","          print(f\"Error convert to load {op} RGB {rgb} : {image_path} {label}\")\n","\n","        image = self.transform(image)\n","\n","        return image, label"]},{"cell_type":"markdown","metadata":{},"source":["# ResNet"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T13:11:13.348938Z","iopub.status.busy":"2024-05-19T13:11:13.348689Z","iopub.status.idle":"2024-05-19T13:11:13.387176Z","shell.execute_reply":"2024-05-19T13:11:13.386121Z","shell.execute_reply.started":"2024-05-19T13:11:13.348915Z"},"trusted":true},"outputs":[],"source":["if torch.cuda.is_available():\n","    device = 'cuda'\n","else :\n","    device = 'cpu'\n","\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T13:11:13.389085Z","iopub.status.busy":"2024-05-19T13:11:13.388433Z","iopub.status.idle":"2024-05-19T13:11:13.403642Z","shell.execute_reply":"2024-05-19T13:11:13.402739Z","shell.execute_reply.started":"2024-05-19T13:11:13.389051Z"},"trusted":true},"outputs":[],"source":["class ResidualBlock(nn.Module):\n","    def __init__(self, input_size, output_size, stride=1, kernel_size=3, padding=1, bias=False):\n","        super(ResidualBlock, self).__init__()\n","        self.cnn1 = nn.Sequential(\n","            nn.Conv2d(input_size, output_size, kernel_size,\n","                      stride, padding, bias=False),\n","            nn.BatchNorm2d(output_size),\n","            nn.ReLU(True)\n","        )\n","        self.cnn2 = nn.Sequential(\n","            nn.Conv2d(output_size, output_size,\n","                      kernel_size, 1, padding, bias=False),\n","            nn.BatchNorm2d(output_size)\n","        )\n","\n","        # Apply He initialization to the convolutional layers\n","        nn.init.kaiming_normal_(self.cnn1[0].weight)\n","        nn.init.kaiming_normal_(self.cnn2[0].weight)\n","\n","        #if the block changes dimensions, then shortcut should change dimensions too\n","        if stride != 1 or input_size != output_size:\n","            \n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(input_size, output_size, kernel_size=1,\n","                          stride=stride, bias=False),\n","                nn.BatchNorm2d(output_size)\n","            )\n","            # Apply He initialization to the shortcut convolutional layers\n","            nn.init.kaiming_normal_(self.shortcut[0].weight)\n","        else:\n","            self.shortcut = nn.Sequential()\n","\n","    def forward(self, x):\n","        residual = x\n","        x = self.cnn1(x)\n","        x = self.cnn2(x)\n","        x += self.shortcut(residual)\n","        x = nn.ReLU(True)(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T13:11:13.405508Z","iopub.status.busy":"2024-05-19T13:11:13.404821Z","iopub.status.idle":"2024-05-19T13:11:13.417669Z","shell.execute_reply":"2024-05-19T13:11:13.416651Z","shell.execute_reply.started":"2024-05-19T13:11:13.405468Z"},"trusted":true},"outputs":[],"source":["class ResNet18(nn.Module):\n","    def __init__(self,num_classes):\n","        super(ResNet18, self).__init__()\n","        self.in_channels = n_kernels\n","        \n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, n_kernels, kernel_size=3,\n","                      stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(n_kernels),\n","            nn.ReLU()\n","        )\n","        \n","        # Apply He initialization to the initial convolutional layer\n","        nn.init.kaiming_normal_(self.features[0].weight)\n","        \n","        self.net = nn.Sequential(\n","            ResidualBlock(n_kernels, n_kernels, stride=1),\n","            ResidualBlock(n_kernels, n_kernels, stride=1),\n","            ResidualBlock(n_kernels, n_kernels*2, stride=2),\n","            ResidualBlock(n_kernels*2, n_kernels*2, stride=1),\n","            ResidualBlock(n_kernels*2, n_kernels*4, stride=2),\n","            ResidualBlock(n_kernels*4, n_kernels*4, stride=1),\n","            ResidualBlock(n_kernels*4, n_kernels*8, stride=2),\n","            ResidualBlock(n_kernels*8, n_kernels*8, stride=1)\n","            \n","        )\n","\n","        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.dropout = nn.Dropout(dropout)\n","        self.classifer = nn.Linear(n_kernels*8, num_classes)\n","\n","\n","    def forward(self, x):\n","        out = self.features(x)\n","        out = self.net(out)\n","        out = self.avg_pool(out)\n","        out = self.dropout(out)\n","        \n","        #flatten\n","        out = out.view(out.size(0), -1)\n","        \n","        out = self.classifer(out)\n","        return out"]},{"cell_type":"markdown","metadata":{},"source":["# Train loop"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T13:11:13.419477Z","iopub.status.busy":"2024-05-19T13:11:13.419069Z","iopub.status.idle":"2024-05-19T13:11:13.437329Z","shell.execute_reply":"2024-05-19T13:11:13.436338Z","shell.execute_reply.started":"2024-05-19T13:11:13.419446Z"},"trusted":true},"outputs":[],"source":["def train(model, trainloader, testloader, n_epochs=n_epochs, learning_rate=learning_rate):\n","\n","    model.to(device)\n","\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","    criterion = nn.CrossEntropyLoss()\n","\n","    train_avg_loss = []\n","    test_avg_loss = []\n","    test_accuracy = []\n","\n","    for i in range(n_epochs):\n","\n","        print(f\"Epoch : {i}\")\n","\n","        train_losses = []\n","        test_losses = []\n","        \n","        # train\n","        for x, y in trainloader:\n","            # send to device\n","            x = x.to(device)\n","            y = y.to(device)\n","\n","            # predict\n","            pred = model(x)\n","            loss = criterion(pred, y)\n","            train_losses.append(loss.detach())\n","\n","            # step\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","        # test\n","        with torch.no_grad():\n","            correct = 0\n","\n","            for x,y in testloader:\n","                x = x.to(device)\n","                y = y.to(device)\n","\n","                pred = model(x)\n","                loss = criterion(pred, y)\n","                test_losses.append(loss.detach())\n","\n","                y_pred = pred.argmax(dim=-1)\n","                correct = correct + (y_pred==y).sum()\n","\n","            accuracy = (correct / len(testloader.dataset))\n","\n","        train_loss = torch.stack(train_losses).mean()\n","        test_loss = torch.stack(test_losses).mean()\n","\n","        print(f\"train_losses : {train_loss}\")\n","        print(f\"test_losses : {test_loss}\")\n","        print(f\"accuracy : {accuracy}\")\n","        \n","        wandb.log({\n","            \"epoch\": i,\n","            \"train loss\": train_loss,\n","            \"test loss\": test_loss,\n","            \"accuracy\": accuracy,\n","        })\n","        \n","        if i % save_every == 0:\n","            torch.save(model.state_dict(), f\"epoch_{i}_model.pt\")\n","            wandb.save(f\"epoch_{i}_model.pt\")\n","\n","        train_avg_loss.append(train_loss)\n","        test_avg_loss.append(test_loss)\n","        test_accuracy.append(accuracy)\n","\n","    return train_avg_loss, test_avg_loss, test_accuracy"]},{"cell_type":"markdown","metadata":{},"source":["# Create dataset / dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T13:11:13.439831Z","iopub.status.busy":"2024-05-19T13:11:13.438867Z","iopub.status.idle":"2024-05-19T13:11:21.296175Z","shell.execute_reply":"2024-05-19T13:11:21.295074Z","shell.execute_reply.started":"2024-05-19T13:11:13.439805Z"},"trusted":true},"outputs":[],"source":["# Instantiate the train and test set\n","\n","# train\n","train_dataset = IntelImageDataset(train=True)\n","\n","# test\n","test_dataset = IntelImageDataset(train=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T13:11:21.302046Z","iopub.status.busy":"2024-05-19T13:11:21.301232Z","iopub.status.idle":"2024-05-19T13:11:21.309503Z","shell.execute_reply":"2024-05-19T13:11:21.308453Z","shell.execute_reply.started":"2024-05-19T13:11:21.302010Z"},"trusted":true},"outputs":[],"source":["# Instantiate the corresponding data loaders\n","\n","# train\n","train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n","\n","# test\n","test_loader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"]},{"cell_type":"markdown","metadata":{},"source":["# Define Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T13:11:21.311752Z","iopub.status.busy":"2024-05-19T13:11:21.310918Z","iopub.status.idle":"2024-05-19T13:11:21.724985Z","shell.execute_reply":"2024-05-19T13:11:21.723841Z","shell.execute_reply.started":"2024-05-19T13:11:21.311718Z"},"trusted":true},"outputs":[],"source":["input_features = [3, 256, 256] # Channels (assuming RGB images), Height, Width\n","output_features = train_dataset.number_of_classes\n","\n","network = ResNet18(num_classes=output_features).to(device)\n","print(network)"]},{"cell_type":"markdown","metadata":{},"source":["# Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T13:11:21.726552Z","iopub.status.busy":"2024-05-19T13:11:21.726264Z","iopub.status.idle":"2024-05-19T13:14:17.819369Z","shell.execute_reply":"2024-05-19T13:14:17.818042Z","shell.execute_reply.started":"2024-05-19T13:11:21.726525Z"},"trusted":true},"outputs":[],"source":["train_avg_loss, test_avg_loss, test_accuracy = train(model=network,\n","                                                     trainloader=train_loader,\n","                                                     testloader=test_loader,\n","                                                     n_epochs=n_epochs,\n","                                                     learning_rate=learning_rate\n","                                                     )"]},{"cell_type":"markdown","metadata":{},"source":["# Plot"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T13:14:17.822979Z","iopub.status.busy":"2024-05-19T13:14:17.821151Z","iopub.status.idle":"2024-05-19T13:14:18.502862Z","shell.execute_reply":"2024-05-19T13:14:18.501791Z","shell.execute_reply.started":"2024-05-19T13:14:17.822923Z"},"trusted":true},"outputs":[],"source":["train_avg_loss_np = torch.tensor(train_avg_loss).detach().cpu().numpy()\n","test_avg_loss_np = torch.tensor(test_avg_loss).detach().cpu().numpy()\n","test_accuracy_np = torch.tensor(test_accuracy).detach().cpu().numpy()\n","\n","plt.figure(figsize=(12, 4))\n","plt.subplot(1, 2, 1)\n","plt.plot(train_avg_loss_np, label='Training Loss')\n","plt.plot(test_avg_loss_np, label='Testing Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training and Testing Loss')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(test_accuracy_np, label='Test Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.title('Test Accuracy')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Finish wandb run"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T13:14:18.504652Z","iopub.status.busy":"2024-05-19T13:14:18.504248Z","iopub.status.idle":"2024-05-19T13:14:21.819692Z","shell.execute_reply":"2024-05-19T13:14:21.818933Z","shell.execute_reply.started":"2024-05-19T13:14:18.504613Z"},"trusted":true},"outputs":[],"source":["# necessary in notebooks\n","wandb.finish()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":111880,"sourceId":269359,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
